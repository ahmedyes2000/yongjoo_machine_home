.\" Automatically generated by Pod::Man 2.25 (Pod::Simple 3.04)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.ie \nF \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    nr % 0
.    rr F
.\}
.el \{\
.    de IX
..
.\}
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "Clair::LM::Ngram 3pm"
.TH Clair::LM::Ngram 3pm "2012-07-09" "perl v5.14.2" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
Ngram \- extract and prune N\-grams from documents
.SH "VERSION"
.IX Header "VERSION"
This documentation refers to Clair::LM::Ngram version 1.0.
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 6
\&    use Clair::Cluster
\&    use Clair::Utils::Ngram qw(load_ngramdict
\&                               dump_ngramdict
\&                               extract_ngrams
\&                               write_ngram_counts
\&                               enforce_count_thresholds);
\&
\&    # Read in documents
\&    my $r_cluster = Clair::Cluster\->new;
\&    $r_cluster\->load_documents("*.html",
\&                               type => \*(Aqhtml\*(Aq,
\&                               filename_id => 1);
\&
\&    # Strip markup and stem resulting document contents, segment into sentences,
\&    #   and extract bigrams, storing the bigram dictionary in $r_ngramdict
\&    my $r_ngramdict = {};
\&    extract_ngrams(cluster   => $r_cluster,
\&                   N         => 2,
\&                   ngramdict => $r_ngramdict,
\&                   format    => \*(Aqhtml\*(Aq,
\&                   stem      => 1,
\&                   segment   => 1,
\&                   verbose   => 1 );
\&
\&    # Remove all bigrams having fewer than 2 occurrences and/or not occurring
\&    #   in the top 100 most frequent
\&    enforce_count_thresholds(N => 2,
\&                             ngramdict => $r_ngramdict,
\&                             mincount  => 2,
\&                             topcount  => 100 );
\&
\&    # Sort bigrams in descending order by count and write bigram dictionary to file
\&    write_ngram_counts(N         => 2,
\&                       ngramdict => $r_ngramdict,
\&                       outfile   => \*(Aqtest.2grams\*(Aq,
\&                       sort      => 1 );
\&
\&    # Serialize bigram dictionary to (network\-ordered) Storable file
\&    dump_ngramdict(N         => 2,
\&                   ngramdict => $r_ngramdict,
\&                   outfile   => \*(Aqtest.2grams.dump\*(Aq );
\&
\&    # Restore N\-gram dictionary from Storable file
\&    my $N;
\&    ($N, $r_ngramdict2) = load_ngramdict(infile => \*(Aqtest.2grams.dump\*(Aq);
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
The Ngram package provides functionality for the extraction of N\-grams from text and \s-1HTML\s0
documents. The resulting N\-gram dictionary can optionally be pruned of low-frequency
N\-grams before being written to a human-readable text file and/or serialized to a
network-ordered Storable file.
.SH "FUNCTIONS"
.IX Header "FUNCTIONS"
.IP "extract_ngrams(cluster => \fI\s-1CLUSTERREF\s0\fR, N => \fI\s-1INTEGER\s0\fR, ngramdict => \fI\s-1HASHREF\s0\fR, format => \fI\s-1SCALAR\s0\fR, stem => \fI\s-1BOOL\s0\fR, segment => \fI\s-1BOOL\s0\fR)" 4
.IX Item "extract_ngrams(cluster => CLUSTERREF, N => INTEGER, ngramdict => HASHREF, format => SCALAR, stem => BOOL, segment => BOOL)"
Extracts N\-grams from the cluster of documents referenced by \fI\s-1CLUSTERREF\s0\fR, storing them
in an N\-level-deep hash referenced by \fI\s-1HASHREF\s0\fR. The documents' format can be \s-1HTML\s0 ('html'),
in which case the documents are stripped of \s-1HTML\s0 markup, or text (the default). Setting
stem to 1 turns stemming on; setting segment to 1 turns sentence segmentation on. With
sentence segmentation on, the text of document is split into sentences prior to each
individual word's being lowercased and (optionally) stemmed.
.Sp
If sentence segmentation is specified, then terms denoting sentence boundaries occur in N\-grams
straddling sentence boundaries and are denoted by <s>. The first N\-gram in a document
then contains N \- 1 sentence boundary terms, followed by the first term occurring in the document
itself. The last N\-gram in a document contains the last term occurring in the document itself,
followed by N \- 1 sentence boundary terms. Such padded N\-grams are counted with sentence
segmentation in order that, from a generative standpoint, the probabilies of occurrence from all
possible documents generated from the extracted N\-gram language model sum to 1.
.IP "write_ngram_counts(N => \fI\s-1INTEGER\s0\fR, ngramdict => \fI\s-1NGRAMDICTREF\s0\fR, outfile => \fI\s-1SCALAR\s0\fR, sort => \fI\s-1BOOL\s0\fR)" 4
.IX Item "write_ngram_counts(N => INTEGER, ngramdict => NGRAMDICTREF, outfile => SCALAR, sort => BOOL)"
Writes the N\-gram dictionary referenced by \fI\s-1NGRAMDICTREF\s0\fR to file \fI\s-1SCALAR\s0\fR. If \fI\s-1BOOL\s0\fR is true, then
the N\-grams are written in decreasing order by number of occurrences.
.IP "(\fI\s-1SCALAR\s0\fR, \fI\s-1HASHREF\s0\fR) = load_ngramdict(infile => \fI\s-1SCALAR\s0\fR)" 4
.IX Item "(SCALAR, HASHREF) = load_ngramdict(infile => SCALAR)"
Restores the N\-gram dictionary in (network-ordered) Storable file \fI\s-1SCALAR\s0\fR. Sets \fI\s-1SCALAR\s0\fR equal to N
and stores a reference to the restored dictionary in \fI\s-1HASHREF\s0\fR.
.IP "dump_ngramdict(N => \fI\s-1INTEGER\s0\fR, ngramdict => \fI\s-1NGRAMDICTREF\s0\fR, outfile => \fI\s-1SCALAR\s0\fR)" 4
.IX Item "dump_ngramdict(N => INTEGER, ngramdict => NGRAMDICTREF, outfile => SCALAR)"
Serializes the N\-gram dictionary referenced by \fI\s-1NGRAMDICTREF\s0\fR, together with the value of N,
to (network-ordered) Storable file \fI\s-1SCALAR\s0\fR.
.IP "enforce_count_thresholds(N => \fI\s-1INTEGER\s0\fR, ngramdict => \fI\s-1NGRAMDICTREF\s0\fR, mincount => \fI\s-1INTEGER_1\s0\fR, topcount => \fI\s-1INTEGER_2\s0\fR)" 4
.IX Item "enforce_count_thresholds(N => INTEGER, ngramdict => NGRAMDICTREF, mincount => INTEGER_1, topcount => INTEGER_2)"
Prunes the N\-gram dictionary referenced by \fI\s-1NGRAMDICTREF\s0\fR of all N\-grams not among the top \fI\s-1INTEGER_2\s0\fR
in occurrences or having fewer than \fI\s-1INTEGER_1\s0\fR occurrences. The order of application of these two
constraints is immaterial.
.SH "DEPENDENCIES"
.IX Header "DEPENDENCIES"
Clair::Cluster, Carp, Exporter, Storable
.SH "BUGS AND LIMITATIONS"
.IX Header "BUGS AND LIMITATIONS"
There are no known bugs in this module.
Please report problems to Dragomir Radev << <radev at umich.edu> >>.
Patches are welcome.
.SH "AUTHOR"
.IX Header "AUTHOR"
Jonathan DePeri << <jmd2118 at columbia.edu> >>
.SH "LICENSE AND COPYRIGHT"
.IX Header "LICENSE AND COPYRIGHT"
This module is free software; you can redistribute it and/or
modify it under the same terms as Perl itself. See perlartistic.
.PP
This program is distributed in the hope that it will be useful,
but \s-1WITHOUT\s0 \s-1ANY\s0 \s-1WARRANTY\s0; without even the implied warranty of
\&\s-1MERCHANTABILITY\s0 or \s-1FITNESS\s0 \s-1FOR\s0 A \s-1PARTICULAR\s0 \s-1PURPOSE\s0.
.PP
Copyright 2007 the Clair group, all rights reserved.
