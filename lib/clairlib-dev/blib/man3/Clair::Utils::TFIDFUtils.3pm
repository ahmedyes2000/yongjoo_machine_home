.\" Automatically generated by Pod::Man 2.25 (Pod::Simple 3.04)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.ie \nF \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    nr % 0
.    rr F
.\}
.el \{\
.    de IX
..
.\}
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "Clair::Utils::TFIDFUtils 3pm"
.TH Clair::Utils::TFIDFUtils 3pm "2012-07-09" "perl v5.14.2" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
TFIDFUtils.pm
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
(See method descriptions for more information.)
.PP
.Vb 12
\&    $res = base10_to_base36($num);
\&    $d = compress_docid($docid);
\&    %counthash = count_hash(@words);
\&    %positionhash = position_hash(@words);
\&    $url = docid_to_url($docid, $corpus);
\&    @urls = document_contains($word, $corpus, $stemmed, $min);
\&    $docid = expand_id($d);
\&    $text = extract_text_from_html($html);
\&    @lcwords = lc_words(@words);
\&    @words = split_words($text, $punc);
\&    @uniqwords = uniq(@allwords);
\&    $docid = url_to_docid($url, $corpus);
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
A set of general purpose routines originally designed for use
in the \s-1TF\s0 and \s-1IDF\s0 building routines, but potentially useful
for other code systems.
.PP
Routines url_to_docid, docid_to_url, compress_docid, and expand_id require
that the database for these conversions be already built.  These can be
built with the method CorpusDownload::build_docno_dbm in module
CorpusDownload.pm
.SH "METHODS"
.IX Header "METHODS"
.SS "split_words"
.IX Subsection "split_words"
\&\f(CW@words\fR = split_words($text, \f(CW$punc\fR);
.PP
Splits the text string into an array of word strings. Whether punctuation
should be preserved can be specified optionally by \f(CW$punc\fR.
.SS "uniq"
.IX Subsection "uniq"
\&\f(CW@uniqwords\fR = uniq(@allwords);
.PP
Removes duplicate words.  Retains original order of unique words.
.SS "count_hash"
.IX Subsection "count_hash"
\&\f(CW%counthash\fR = count_hash(@words);
.PP
Computes and returns a hash with \f(CW$counthash\fR{$w} set to number of
occurrences of element \f(CW$w\fR in the array \f(CW@words\fR.
.SS "position_hash"
.IX Subsection "position_hash"
\&\f(CW%positionhash\fR = position_hash(@words);
.PP
Computes and returns a position table with \f(CW$positionhash\fR{$w} set to
a reference to an array containing the positional indices of the
occurrences of \f(CW$w\fR in \f(CW@words\fR (positions start at 1, not 0)
.SS "extract_text_from_html"
.IX Subsection "extract_text_from_html"
\&\f(CW$text\fR = extract_text_from_html($html);
.PP
Removes comments, scripts, stylesheets and other \s-1HTML\s0 tags and
returns remainder.
.SS "lc_words"
.IX Subsection "lc_words"
\&\f(CW@lcwords\fR = lc_words(@words);
.PP
Makes all words in \f(CW@words\fR lower case.
.SS "base10_to_base36"
.IX Subsection "base10_to_base36"
\&\f(CW$res\fR = base10_to_base36($num);
.PP
Returns a string representing integer \f(CW$num\fR in base 36, with
a \-> 10, b \-> 11, ..., y \-> 34, z \-> 35.
.SS "compress_docid"
.IX Subsection "compress_docid"
\&\f(CW$d\fR = compress_docid($docid);
.PP
Looks this (\s-1ASCII\s0) docid up in the compress-docid database and returns
the compressed form (i.e., the base36 unique form).
.PP
Assumes the compress-docid database is in
\&\f(CW$TFIDF_DIR\fR/$corpus\-compress\-docid.dir and
\&\f(CW$TFIDF_DIR\fR/$corpus\-compress\-docid.pag
.PP
Quits if it isn't.
.PP
Requires environment variable \f(CW$TFIDF_DIR\fR.
.SS "expand_id"
.IX Subsection "expand_id"
\&\f(CW$docid\fR = expand_id($d);
.PP
Looks up this compressed docid (i.e., base36 unique form) and returns
its long (\s-1ASCII\s0) form.
.PP
Assumes the expand-docid database is in
\&\f(CW$TFIDF_DIR\fR/$corpus\-expand\-docid.dir and
\&\f(CW$TFIDF_DIR\fR/$corpus\-expand\-docid.pag
.PP
Quits if it isn't.
.PP
Requires environment variable \f(CW$TFIDF_DIR\fR.
.SS "url_to_docid"
.IX Subsection "url_to_docid"
\&\f(CW$docid\fR = url_to_docid($url, \f(CW$corpus\fR);
.PP
Looks this \s-1URL\s0 up in the url-to-docid database and returns
the associated document \s-1ID\s0.
.PP
Assumes the url-to-docid database is in
\&\f(CW$TFIDF_DIR\fR/$corpus\-url\-to\-docid.dir and
\&\f(CW$TFIDF_DIR\fR/$corpus\-url\-to\-docid.pag
.PP
Quits if it isn't.
.PP
Requires environment variable \f(CW$TFIDF_DIR\fR.
.SS "docid_to_url"
.IX Subsection "docid_to_url"
\&\f(CW$url\fR = docid_to_url($docid, \f(CW$corpus\fR);
.PP
Looks this doc \s-1ID\s0 up in the docid-to-url database and returns
the associated \s-1URL\s0.
.PP
Assumes the docid-to-url database is in
\&\f(CW$TFIDF_DIR\fR/$corpus\-docid\-to\-url.dir and
\&\f(CW$TFIDF_DIR\fR/$corpus\-docid\-to\-url.pag
.PP
Quits if it isn't.
.PP
Requires environment variable \f(CW$TFIDF_DIR\fR.
.SS "document_contains"
.IX Subsection "document_contains"
\&\f(CW@urls\fR = document_contains($word, \f(CW$corpus\fR, \f(CW$stemmed\fR, \f(CW$min\fR);
.PP
Returns a list of URLs or documents in \f(CW$corpus\fR that contain \f(CW$word\fR.
Parameters \f(CW$word\fR and \f(CW$corpus\fR are required.
.PP
Pass \-s to (optional) parameter \f(CW$stemmed\fR to stem the word before looking
for it, or pass nothing to supress stemming.  (Default is \-s.)
.PP
Pass \f(CW$min\fR to (optional) parameter to set the minimum
number or occurrences of the \f(CW$word\fR that cause the \s-1URL\s0 to be
returned.  (Default is 1.)
.PP
Requires environment variable \f(CW$TFIDF_DIR\fR.
.SH "METHODS FROM Clair::StringManip"
.IX Header "METHODS FROM Clair::StringManip"
.SS "stem"
.IX Subsection "stem"
Takes either the string or the arrayref and stems the tokens (words)
using Lingua::Stem module. Return value can be either string or arrayref
based on the last parameter.
.SS "strip"
.IX Subsection "strip"
Strips meta charcters from the string.
.SS "normalize_input"
.IX Subsection "normalize_input"
Used for user query string processing. It parses and tokenizes the query 
string into appropriate segments.
.SH "ENVIRONMENT VARIABLES"
.IX Header "ENVIRONMENT VARIABLES"
The variable \f(CW$TFIDF_DIR\fR must be set prior to execution of
most routines in this module.
.PP
Environment variable \f(CW$TFIDF_DIR\fR should be set to the directory
above the \s-1TF\s0 is in.  For example, if the \s-1TF\s0 is in the directory
\&\*(L"/data0/projects/tfidf/corpus\-data/kzoo\-tf\-s\*(R", \f(CW$TFIDF_DIR\fR
should be set to \*(L"/data0/projects/tfidf/corpus\-data\*(R".
