.\" Automatically generated by Pod::Man 2.25 (Pod::Simple 3.04)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.ie \nF \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    nr % 0
.    rr F
.\}
.el \{\
.    de IX
..
.\}
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "UtilTut 3pm"
.TH UtilTut 3pm "2012-07-09" "perl v5.14.2" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SS "Clairlib Network Processing Utilities Tutorial"
.IX Subsection "Clairlib Network Processing Utilities Tutorial"
A tutorial explaining how to use the Clairlib library and tools to create a network from a group of files and process that network to extract information.
.PP
\fIIntroduction\fR
.IX Subsection "Introduction"
.PP
This tutorial will walk you through downloading files, creating a corpus from them, creating a network from the corpus, and extracting information along the way.  We'll be using utilities included in the Clairlib package to do the work.
.PP
Before beginning, install the clairlib package.  To do so, follow the instructions at:
.PP
.Vb 1
\& http://belobog.si.umich.edu/mediawiki/index.php/Installation.
.Ve
.PP
The best way to use this document is to read all the way through as each command is explained.  The commands at the end of the tutorial in the code section.
.PP
\fIGenerating the corpus\fR
.IX Subsection "Generating the corpus"
.PP
The first thing we will need is a corpus of files to run our tests against.  As an example we will be using a set of files extracted from Wikipedia.  We'll first download those files into a folder:
.PP
.Vb 1
\& mkdir corpus
.Ve
.PP
We'll use the 'wget' command to download the files.  The \-r means to recursively get all of the files in the folder, \-nd means don't create the directory path, and \-nc means only get one copy of each file:
.PP
.Vb 3
\& cd corpus
\& wget \-r \-nd \-nc http://belobog.si.umich.edu/clair/corpora/chemical
\& cd ..
.Ve
.PP
Now that we have our files, we can create the corpus.  To do this we'll use the 'directory_to_corpus.pl' utility.  The options used here are fairly consistent for all utilities:  \-\-corpus, or \-c, refers to the name of the corpus we are creating.  This should be something fairly simple, since we use it often and it is used to name several of the files we'll be creating.  In this case, we call our corpus 'chemical'.  \-\-base, or \-b, refers to the base directory of our corpus' data files.  A common practice is to use 'produced'.  Lastly \-\-directory, or \-d, refers to the directory where our files to be converted are located:
.PP
.Vb 2
\& directory_to_corpus.pl \-\-corpus chemical \-\-base produced \e
\&  \-\-directory corpus
.Ve
.PP
Now that our corpus has been organized, we'll index it so we can then start extacting data from it.  To do that we'll use 'index_corpus.pl'.  Again, we'll specify the corpus name and the base directory where the index files should be produced:
.PP
.Vb 1
\& index_corpus.pl \-\-corpus chemical \-\-base produced
.Ve
.PP
We've now got our corpus and our indices and are ready to extract data.
.PP
\fITfs and Idfs\fR
.IX Subsection "Tfs and Idfs"
.PP
First we'll run a query for the term frequency of a single term.  To do this we'll use 'tf_query.pl'.  Let's query 'health':
.PP
.Vb 1
\& tf_query.pl \-c chemical \-b produced \-q health
.Ve
.PP
This outputs a list of the files in our corpus which contain the term 'health' and the number of times those terms occur in that file.  To get term frequencies for all terms in the corpus, pass the \-\-all option:
.PP
.Vb 1
\& tf_query.pl \-c chemical \-b produced \-\-all
.Ve
.PP
This returns a list of terms, their frequencies, and the number of documents each occurs in.
.PP
In order to see the full list of term frequencies for stemmed terms, pass the stemmed option:
.PP
.Vb 1
\& tf_query.pl \-c chemical \-b produced \-\-stemmed \-\-all
.Ve
.PP
Next we'll run a query for the inverse document frequency of a single term.  To do this we'll use 'idf_query'.  Again, we'll query 'health':
.PP
.Vb 1
\& idf_query.pl \-c chemical \-b produced \-q health
.Ve
.PP
We can also pass the \-\-all option to idf_query.pl to get a list of idf's for all terms in the corpus:
.PP
.Vb 1
\& idf_query.pl \-c chemical \-b produced \-\-all
.Ve
.PP
\fICreating a Network\fR
.IX Subsection "Creating a Network"
.PP
We now have a corpus from which we can extract some data.  Next we'll create a network from this corpus.  To do this, we'll use 'corpus_to_network.pl'.  This command creates a network of hyperlinks from our corpus.  It produces a graph file with each line containing two linked nodes.  This command requires a specified output file which we'll call 'chemical.graph':
.PP
.Vb 1
\& corpus_to_network.pl \-c chemical \-b produced \-o chemical.graph
.Ve
.PP
Now we can gather some data on this network.  To do that we'll run 'print_network_stats.pl' on our graph file.  This command can be used to produce many different types of data.  The easiest way to use it is with the \-\-all option, which run all of its various tests.  We'll redirect its output to a file:
.PP
.Vb 1
\& print_network_stats.pl \-i chemical.graph \-\-all > chemical.graph.stats
.Ve
.PP
If we now look at 'chemical.graph.stats' we can see statistics for our network including numbers of nodes and edges, degree statistics, clustering coefficients, and path statistics.  This command also creates three centrality files (betweenness, closeness, and degree) which are lists of all terms and their centralities.
.PP
\fIConclusions\fR
.IX Subsection "Conclusions"
.PP
With the tools described above you should be able to create a corpus from a set of files and extract statistics from that corpus.  For additional functionality or to get more information on the utilites used, go to
.PP
.Vb 1
\& http://belobog.si.umich.edu/mediawiki/index.php/Documentation.
.Ve
.PP
\fI\s-1CODE\s0\fR
.IX Subsection "CODE"
.PP
This is a list of all of the commands used in this tutorial:
.PP
.Vb 10
\& mkdir corpus
\& cd corpus
\& wget \-r \-nd \-nc http://belobog.si.umich.edu/clair/corpora/chemical
\& cd ..
\& directory_to_corpus.pl \-\-corpus chemical \-\-base produced \e
\&  \-\-directory corpus
\& index_corpus.pl \-\-corpus chemical \-\-base produced
\& tf_query.pl \-c chemical \-b produced \-q health
\& tf_query.pl \-c chemical \-b produced \-\-all
\& idf_query.pl \-c chemical \-b produced \-q health
\& idf_query.pl \-c chemical \-b produced \-\-all
\& corpus_to_network.pl \-c chemical \-b produced \-o chemical.graph
\& print_network_stats.pl \-i chemical.graph \-\-all > chemical.graph.stats
.Ve
